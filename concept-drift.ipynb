{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from classifier.detector_classifier import DetectorClassifier\n",
    "from concept_drift.adwin import AdWin\n",
    "from concept_drift.page_hinkley import PageHinkley\n",
    "from evaluation.prequential import prequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTILS = \"../utils/\"\n",
    "if UTILS not in sys.path:\n",
    "    sys.path.append(\"../utils/\")\n",
    "\n",
    "from util import ql_ref_date\n",
    "from util import recover_download_site_mab\n",
    "from util import get_onlysite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(temp, dir_ctrl):\n",
    "    dir_ctrl = os.path.join(temp, dir_ctrl)\n",
    "    print(\"Reading\",dir_ctrl)\n",
    "    files = glob.glob(os.path.join(dir_ctrl, '*.log'))\n",
    "    sarss = []\n",
    "    sars = None\n",
    "    file_id = 0\n",
    "    for filename in sorted(files):\n",
    "        ref = ql_ref_date(filename, split_text1='mab1-').replace('T', 'Z')\n",
    "        site1 = get_onlysite(recover_download_site_mab(relative_path=temp, sta=1, ref_date=ref, prefix='sta-mab-'))\n",
    "        site2 = get_onlysite(recover_download_site_mab(relative_path=temp, sta=2, ref_date=ref, prefix='sta-mab-'))\n",
    "\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            _l = lines[i]\n",
    "            if 'iteration' in _l:\n",
    "                sars = None\n",
    "            if 'Frequency: ' in _l:\n",
    "                f = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", _l)\n",
    "                if len(f) == 10:\n",
    "                    # ok\n",
    "                    sars = dict(zip(['Frequency', 'Medium busy', 'Busy time', 'Active time'], f[6:]))\n",
    "            elif sars is not None:\n",
    "                # ok, got at least Frequency...\n",
    "                if '] AP0 txpower:' in _l:\n",
    "                    f = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", _l)\n",
    "                    if len(f) == 11:\n",
    "                        sars.update(dict(zip(['txpower', 'new_txpower', 'channel', 'new_channel'], f[7:])))\n",
    "                    if 'new Medium busy' in sars:\n",
    "                        sars.update({'file_id': file_id})\n",
    "                        sars.update({'sites': (site1, site2)})\n",
    "                        file_id += 1\n",
    "                        sarss.append(sars)\n",
    "                    sars = None\n",
    "                elif '] rewards:' in _l:\n",
    "                    sars['r'] = _l.split('] rewards:')[1].replace('\\n', '').strip()\n",
    "                    if 'None' in sars['r'] :\n",
    "                        sars = None  # error, skip\n",
    "                    else:\n",
    "                        try:\n",
    "                            ## find new state\n",
    "                            for j in range(1, 10):\n",
    "                                _ll = lines[i + j]\n",
    "                                if 'Frequency: ' in _ll:                                  \n",
    "                                    f = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", _ll)\n",
    "                                    if len(f) == 10:\n",
    "                                        # ok\n",
    "                                        new_sars = dict(zip(['new Medium busy', 'new Busy time', 'new Active time'], f[7:]))\n",
    "                                        sars.update(new_sars)\n",
    "                                    break\n",
    "                        except (KeyError, IndexError):\n",
    "                            sars = None  # error skip\n",
    "    return sarss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a temporary dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP = 'temp'\n",
    "if not os.path.exists(TEMP):\n",
    "    os.mkdir(TEMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract MAB results to TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../MAB1/data/*.tar.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sta2.tar.xz\n",
      "Extracting removed.tar.xz\n",
      "Extracting ap.tar.xz\n",
      "Extracting ctrl.tar.xz\n",
      "Extracting sta1.tar.xz\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    print(\"Extracting {}\".format(os.path.basename(f)))\n",
    "    s = \"tar -C {} -xJf {}\".format(TEMP, f)\n",
    "    # print(s)\n",
    "    os.system(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading temp/ctrl\n"
     ]
    }
   ],
   "source": [
    "sarss = get_values(TEMP, 'ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 237646\n"
     ]
    }
   ],
   "source": [
    "print(\"Found\", len(sarss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"rm -fr {}\".format(TEMP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(sarss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = data['r'].astype('float')\n",
    "y = np.sign(np.concatenate(([1], y[1:].values - y[:-1].values)))\n",
    "y[y==-1] = 0  # y will have only 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data[['Active time', 'Medium busy', 'channel',\n",
    "       'new Active time', 'new Busy time', 'new Medium busy',\n",
    "       'new_channel', 'new_txpower', 'txpower']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Drift ADWIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ADWIN__\n",
    "\n",
    "* BIFET, Albert; GAVALDA, Ricard. Learning from time-changing data with adaptive windowing. In: Proceedings of the 2007 SIAM international conference on data mining. Society for Industrial and Applied Mathematics, 2007. p. 443-448.\n",
    "\n",
    "\n",
    "__Page-Hinckley Test__\n",
    "\n",
    "* GAMA, João; SEBASTIÃO, Raquel; RODRIGUES, Pedro Pereira. On evaluating stream learning algorithms. Machine learning, v. 90, n. 3, p. 317-346, 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_drift(X, y, \n",
    "                    n_train=1000, w=100,\n",
    "                    lambda_=50,\n",
    "                    clfs_label=[\"GaussianNB\", \"Page-Hinkley\", \"AdWin\"],\n",
    "                    plot_circles=[\"AdWin\"]):\n",
    "    clfs = []\n",
    "    if \"GaussianNB\" in clfs_label:\n",
    "        clfs.append(GaussianNB())\n",
    "    if \"Page-Hinkley\" in clfs_label:\n",
    "        clfs.append(DetectorClassifier(GaussianNB(), PageHinkley(lambda_=lambda_), np.unique(y)))\n",
    "    if \"AdWin\" in clfs_label:\n",
    "        clfs.append(DetectorClassifier(GaussianNB(), AdWin(), np.unique(y)))\n",
    "\n",
    "    plt.title(\"Accuracy (exact match)\")\n",
    "    plt.xlabel(\"Instances\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    y_max = y.shape[0]\n",
    "    ax.set_xlim((0, y_max))\n",
    "    ax.set_ylim((0, 1))\n",
    "\n",
    "    ellipse_y = 0.05\n",
    "    ellipse_x = ellipse_y * y_max / 2\n",
    "    ellipse_color = {\"GaussianNB\": 'blue', \"Page-Hinkley\":'orange', \"AdWin\":'green'}\n",
    "    \n",
    "    for i in range(len(clfs)):\n",
    "        print(\"\\n{}:\".format(clfs_label[i]))\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            y_pre, time = prequential(X, y, clfs[i], n_train)\n",
    "        \n",
    "        estimator = (y[n_train:] == y_pre) * 1\n",
    "        acc_run = np.convolve(estimator, np.ones((w,)) / w, 'same')\n",
    "\n",
    "        if clfs[i].__class__.__name__ == \"DetectorClassifier\":\n",
    "            print(\"Drift detection: {}\".format(clfs[i].change_detected))\n",
    "            \n",
    "            if len(plot_circles) > 0 and clfs_label[i] in plot_circles and len(clfs[i].detected_elements) > 0:\n",
    "                acc = [acc_run[d] for d in clfs[i].detected_elements]\n",
    "                points = [(x, y) for x, y in zip(clfs[i].detected_elements, acc)]\n",
    "                print(\"Drift detected in\", str(points))\n",
    "                for x, y, in points:\n",
    "                    # c = plt.Circle((x, y), 0.1, color='r')\n",
    "                    c = Ellipse(xy=(x, y), width=ellipse_x, height=ellipse_y, angle=0, \n",
    "                                color=ellipse_color[clfs_label[i]], fill=False)\n",
    "                    ax.add_artist(c)\n",
    "\n",
    "        print(\"Mean acc within the window {}: {}\".format(w, np.mean(acc_run)))\n",
    "        if len(clfs_label) == 1:\n",
    "            plt.plot(acc_run, \"-\", color=ellipse_color[clfs_label[i]])\n",
    "        else:\n",
    "            plt.plot(acc_run, \"-\", label=clfs_label[i], color=ellipse_color[clfs_label[i]])\n",
    "        \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 60 * 30  # 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# varying the window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GaussianNB:\n",
      "Mean acc within the window 16: 0.8669349471362288\n",
      "\n",
      "Page-Hinkley:\n",
      "Drift detection: 72\n",
      "Mean acc within the window 16: 0.7387009499421077\n",
      "\n",
      "AdWin:\n"
     ]
    }
   ],
   "source": [
    "for w in [16, 32, 64, 128, 256, 512]:\n",
    "    calculate_drift(X, y, n_train=1000, w=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(sarss)\n",
    "data = data[data['sites'] == ('google', 'google')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['r'].astype('float')\n",
    "y = np.sign(np.concatenate(([1], y[1:].values - y[:-1].values)))\n",
    "y[y==-1] = 0  # y will have only 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Active time', 'Medium busy', 'channel',\n",
    "       'new Active time', 'new Busy time', 'new Medium busy',\n",
    "       'new_channel', 'new_txpower', 'txpower']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_drift(X, y, n_train=1000, w=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only one experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interval = 1800\n",
    "for i in range(10):\n",
    "    li = interval * i\n",
    "    ls = li + 1800\n",
    "    y1 = y[li:ls]\n",
    "    X1 = X[li:ls]\n",
    "    print(\"Experiment #{} from {} to {}\".format(i, li, ls))\n",
    "    calculate_drift(X1, y1, n_train=100, w=16, clfs_label=[\"Page-Hinkley\", \"AdWin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing lambda from Page-Hinkley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 1800\n",
    "for lambda_ in [10, 20, 30, 40, 50, 100]:\n",
    "    for i in range(1):\n",
    "        li = interval * i\n",
    "        ls = li + 1800\n",
    "        y1 = y[li:ls]\n",
    "        X1 = X[li:ls]\n",
    "        print(\"Experiment #{} from {} to {}\".format(i, li, ls))\n",
    "        calculate_drift(X1, y1, n_train=100, w=16, lambda_=lambda_, clfs_label=[\"Page-Hinkley\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
